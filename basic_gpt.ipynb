{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c1b6619-48a0-4b63-90a8-b2a8d791864c",
   "metadata": {},
   "source": [
    "# Building LLMs from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "193396d1-f719-4c47-8730-32926253790c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "type": "bar",
         "y": [
          2,
          1,
          3
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "A Figure Displayed with fig.show()"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "import keras.ops as K\n",
    "import re\n",
    "import tiktoken # Byte Pair Encoding \n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "fig = go.Figure(\n",
    "    data=[go.Bar(y=[2, 1, 3])],\n",
    "    layout_title_text=\"A Figure Displayed with fig.show()\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7537487c-2f2c-49fc-9b40-05486019a90e",
   "metadata": {},
   "source": [
    "Load the shakespeare text dataset: contains 100,000 characters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "280a135d-4d41-45fb-8787-0b2b10a3d292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n",
      "\n",
      "length of the entire text file: 1003854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 16:49:04.984277: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-03-30 16:49:04.984313: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:137] retrieving CUDA diagnostic information for host: ragab\n",
      "2025-03-30 16:49:04.984317: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:144] hostname: ragab\n",
      "2025-03-30 16:49:04.984475: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:168] libcuda reported version is: 560.35.3\n",
      "2025-03-30 16:49:04.984497: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:172] kernel reported version is: 560.35.3\n",
      "2025-03-30 16:49:04.984500: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:259] kernel version seems to match DSO: 560.35.3\n",
      "2025-03-30 16:49:05.108383: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:376] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n",
      "2025-03-30 16:49:05.112771: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "dataset = tfds.load(name='tiny_shakespeare')\n",
    "\n",
    "train = dataset['train']\n",
    "for text in train:\n",
    "    x = text['text'].numpy().decode('utf-8')\n",
    "print(x[:100])\n",
    "print(f\"\\nlength of the entire text file: {len(x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a67f9d-e067-4cec-a767-ef67dbbc6e74",
   "metadata": {},
   "source": [
    "## Setting up a custom simple tokenizer \n",
    "Converts normal text into tokens using regex ----> then converts from tokens into token ids using a custom class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3901bed-9d89-4b7e-b0f7-79750a6afba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['First', ' ', 'Citizen', ':', '', '\\n', 'Before', ' ', 'we', ' ', 'proceed', ' ', 'any', ' ', 'further', ',', '', ' ', 'hear', ' ', 'me', ' ', 'speak', '.', '', '\\n', '', '\\n', 'All', ':', '', '\\n', 'Speak', ',', '', ' ', 'speak', '.', '', '\\n', '', '\\n', 'First', ' ', 'Citizen', ':', '', '\\n', 'You', ' ', 'are', ' ', 'all', ' ', 'resolved', ' ', 'rather', ' ', 'to', ' ', 'die', ' ', 'than', ' ', 'to', ' ', 'famish', '?', '', '\\n', '', '\\n', 'All', ':', '', '\\n', 'Resolved', '.', '', ' ', 'resolved', '.', '', '\\n', '', '\\n', 'First', ' ', 'Citizen', ':', '', '\\n', 'First', ',', '', ' ', 'you', ' ', 'know', ' ']\n"
     ]
    }
   ],
   "source": [
    "tokens = re.split(r'([,.:;?_!\"()\\']|--|\\s)', x)\n",
    "print(tokens[:100])\n",
    "\n",
    "vocabulary = sorted(set(tokens))\n",
    "\n",
    "# Create a Dictionary with additional special tokens (\"<|unk|>\", \"<|eos|>\") \n",
    "# for an unkown word or the end of text (incase I train with multiple text sources).\\\n",
    "\n",
    "dictionary = {item:value for value, item in enumerate(vocabulary)}\n",
    "dictionary[\"<|unk|>\"] = len(dictionary)\n",
    "dictionary[\"<|eos|>\"] = len(dictionary)\n",
    "#dictionary[\"<|bos|>\"] = len(dictionary)\n",
    "#dictionary[\"<|pad|>\"] = len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a7958d9-b15d-447c-bdbc-752f481e4dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTockenizer:\n",
    "    \"\"\"\n",
    "    A simple tokenizer which using a dictionary converts the text into token ids \n",
    "    \"\"\"\n",
    "    def __init__(self, dictionary):\n",
    "        self.dictionary = dictionary\n",
    "        self.dictionary_reverse = {value:item for item, value in dictionary.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        split = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        tokens = list()\n",
    "        for item in split:\n",
    "            try: \n",
    "                tokens.append(self.dictionary[item])\n",
    "            except:\n",
    "                tokens.append(self.dictionary[\"<|unk|>\"])\n",
    "                \n",
    "        return tokens\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        text = \"\".join([self.dictionary_reverse[token] for token in tokens])\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb424cff-46a0-4020-b669-c8a95981fe4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[864, 2, 457, 11, 0, 1, 249, 2, 12630, 2]\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTockenizer(dictionary)\n",
    "tokens = tokenizer.encode(x)\n",
    "print(tokens[:10])\n",
    "\n",
    "text = tokenizer.decode(tokens)\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8201767f-f8ff-48aa-a1e0-523d66f4290a",
   "metadata": {},
   "source": [
    "## Using the GPT2 tokenizer form the tiktoken library\n",
    "The GPT2 tokenizer uses byte pair encoding which creates tokens for entire words and for sub-word characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95d04f67-0d2e-4044-baf7-fba801c393ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5962, 22307, 25, 198, 8421, 356, 5120, 597, 2252, 11, 3285, 502, 2740, 13, 198, 198, 3237, 25, 198, 5248, 461, 11, 2740, 13, 198, 198, 5962, 22307, 25, 198, 1639, 389, 477, 12939, 2138, 284, 4656, 621, 284, 1145, 680, 30, 198, 198, 3237, 25, 198, 4965, 5634, 13]\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved.\n"
     ]
    }
   ],
   "source": [
    "tiktok = tiktoken.get_encoding(\"gpt2\")\n",
    "integers = tiktok.encode(x, allowed_special={\"<|eos|>\"})\n",
    "print(integers[:50])\n",
    "\n",
    "strings = tiktok.decode(integers[:50])\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28b1e22-a909-45fa-ab6b-7f8cabb87fab",
   "metadata": {},
   "source": [
    "## Setting up the input and target values using the Windowing technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfdb1b27-3a54-4fd7-a55f-f7769dbf4ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First-------> Citizen\n",
      "First Citizen------->:\n",
      "First Citizen:------->\n",
      "\n",
      "First Citizen:\n",
      "------->Before\n"
     ]
    }
   ],
   "source": [
    "context_size = 4\n",
    "for i in range(1, context_size+1):\n",
    "    inputs = integers[:i]\n",
    "    target = integers[i]\n",
    "    print(tiktok.decode(inputs) + '------->' + tiktok.decode([target]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f48df1-f298-4a97-a7cd-b5898ad6218a",
   "metadata": {},
   "source": [
    "## Create a Custom DataLoader to load the Data into TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd22a60a-ecf5-4036-8d14-7f43556fff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    A custom data loader which loads data using the tiktoken tokenizer\n",
    "    into Tensorflow, creating input and target values using the windowing technique\n",
    "    \"\"\"\n",
    "    def __init__(self, text, stride, max_length):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "        token_ids = tokenizer.encode(text, allowed_special={\"<|eos|>\"})\n",
    "        \n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            self.input_ids.append(token_ids[i:i+max_length])\n",
    "            self.target_ids.append(token_ids[i+1:i+1+max_length])\n",
    "            \n",
    "        # Convert lists to TensorFlow tensors\n",
    "        self.input_ids = tf.convert_to_tensor(self.input_ids, dtype=tf.int32)\n",
    "        self.target_ids = tf.convert_to_tensor(self.target_ids, dtype=tf.int32)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "    \n",
    "    def load_data(self, batch_size=8, shuffle=False):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((self.input_ids, self.target_ids)) \n",
    "        # Shuffle the dataset if required\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "\n",
    "        # Batch the dataset\n",
    "        dataset = dataset.batch(batch_size)\n",
    "\n",
    "        # Prefetch the dataset for better performance\n",
    "        dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "419895b1-5bae-4ae6-93aa-58635863bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader(x, 2, 10)\n",
    "dataset = data.load_data(batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8457be4a-1967-49d1-8714-72355686f031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(1, 10), dtype=int32, numpy=\n",
      "array([[ 5962, 22307,    25,   198,  8421,   356,  5120,   597,  2252,\n",
      "           11]], dtype=int32)>, <tf.Tensor: shape=(1, 10), dtype=int32, numpy=\n",
      "array([[22307,    25,   198,  8421,   356,  5120,   597,  2252,    11,\n",
      "         3285]], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9484282-826e-4090-a6af-45ce07aac2d7",
   "metadata": {},
   "source": [
    "## Creating a token embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b65a24aa-dc01-483d-bb6d-f1939060f518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 100), dtype=int32, numpy=\n",
       "array([[ 5962, 22307,    25,   198,  8421,   356,  5120,   597,  2252,\n",
       "           11,  3285,   502,  2740,    13,   198,   198,  3237,    25,\n",
       "          198,  5248,   461,    11,  2740,    13,   198,   198,  5962,\n",
       "        22307,    25,   198,  1639,   389,   477, 12939,  2138,   284,\n",
       "         4656,   621,   284,  1145,   680,    30,   198,   198,  3237,\n",
       "           25,   198,  4965,  5634,    13, 12939,    13,   198,   198,\n",
       "         5962, 22307,    25,   198,  5962,    11,   345,   760,   327,\n",
       "         1872,   385,  1526, 28599,   318,  4039,  4472,   284,   262,\n",
       "          661,    13,   198,   198,  3237,    25,   198,  1135,   760,\n",
       "          470,    11,   356,   760,   470,    13,   198,   198,  5962,\n",
       "        22307,    25,   198,  5756,   514,  1494,   683,    11,   290,\n",
       "          356],\n",
       "       [ 8421,   356,  5120,   597,  2252,    11,  3285,   502,  2740,\n",
       "           13,   198,   198,  3237,    25,   198,  5248,   461,    11,\n",
       "         2740,    13,   198,   198,  5962, 22307,    25,   198,  1639,\n",
       "          389,   477, 12939,  2138,   284,  4656,   621,   284,  1145,\n",
       "          680,    30,   198,   198,  3237,    25,   198,  4965,  5634,\n",
       "           13, 12939,    13,   198,   198,  5962, 22307,    25,   198,\n",
       "         5962,    11,   345,   760,   327,  1872,   385,  1526, 28599,\n",
       "          318,  4039,  4472,   284,   262,   661,    13,   198,   198,\n",
       "         3237,    25,   198,  1135,   760,   470,    11,   356,   760,\n",
       "          470,    13,   198,   198,  5962, 22307,    25,   198,  5756,\n",
       "          514,  1494,   683,    11,   290,   356,  1183,   423, 11676,\n",
       "          379],\n",
       "       [ 2252,    11,  3285,   502,  2740,    13,   198,   198,  3237,\n",
       "           25,   198,  5248,   461,    11,  2740,    13,   198,   198,\n",
       "         5962, 22307,    25,   198,  1639,   389,   477, 12939,  2138,\n",
       "          284,  4656,   621,   284,  1145,   680,    30,   198,   198,\n",
       "         3237,    25,   198,  4965,  5634,    13, 12939,    13,   198,\n",
       "          198,  5962, 22307,    25,   198,  5962,    11,   345,   760,\n",
       "          327,  1872,   385,  1526, 28599,   318,  4039,  4472,   284,\n",
       "          262,   661,    13,   198,   198,  3237,    25,   198,  1135,\n",
       "          760,   470,    11,   356,   760,   470,    13,   198,   198,\n",
       "         5962, 22307,    25,   198,  5756,   514,  1494,   683,    11,\n",
       "          290,   356,  1183,   423, 11676,   379,   674,   898,  2756,\n",
       "           13],\n",
       "       [ 2740,    13,   198,   198,  3237,    25,   198,  5248,   461,\n",
       "           11,  2740,    13,   198,   198,  5962, 22307,    25,   198,\n",
       "         1639,   389,   477, 12939,  2138,   284,  4656,   621,   284,\n",
       "         1145,   680,    30,   198,   198,  3237,    25,   198,  4965,\n",
       "         5634,    13, 12939,    13,   198,   198,  5962, 22307,    25,\n",
       "          198,  5962,    11,   345,   760,   327,  1872,   385,  1526,\n",
       "        28599,   318,  4039,  4472,   284,   262,   661,    13,   198,\n",
       "          198,  3237,    25,   198,  1135,   760,   470,    11,   356,\n",
       "          760,   470,    13,   198,   198,  5962, 22307,    25,   198,\n",
       "         5756,   514,  1494,   683,    11,   290,   356,  1183,   423,\n",
       "        11676,   379,   674,   898,  2756,    13,   198,  3792,   470,\n",
       "          257],\n",
       "       [ 3237,    25,   198,  5248,   461,    11,  2740,    13,   198,\n",
       "          198,  5962, 22307,    25,   198,  1639,   389,   477, 12939,\n",
       "         2138,   284,  4656,   621,   284,  1145,   680,    30,   198,\n",
       "          198,  3237,    25,   198,  4965,  5634,    13, 12939,    13,\n",
       "          198,   198,  5962, 22307,    25,   198,  5962,    11,   345,\n",
       "          760,   327,  1872,   385,  1526, 28599,   318,  4039,  4472,\n",
       "          284,   262,   661,    13,   198,   198,  3237,    25,   198,\n",
       "         1135,   760,   470,    11,   356,   760,   470,    13,   198,\n",
       "          198,  5962, 22307,    25,   198,  5756,   514,  1494,   683,\n",
       "           11,   290,   356,  1183,   423, 11676,   379,   674,   898,\n",
       "         2756,    13,   198,  3792,   470,   257, 15593,    30,   198,\n",
       "          198],\n",
       "       [  461,    11,  2740,    13,   198,   198,  5962, 22307,    25,\n",
       "          198,  1639,   389,   477, 12939,  2138,   284,  4656,   621,\n",
       "          284,  1145,   680,    30,   198,   198,  3237,    25,   198,\n",
       "         4965,  5634,    13, 12939,    13,   198,   198,  5962, 22307,\n",
       "           25,   198,  5962,    11,   345,   760,   327,  1872,   385,\n",
       "         1526, 28599,   318,  4039,  4472,   284,   262,   661,    13,\n",
       "          198,   198,  3237,    25,   198,  1135,   760,   470,    11,\n",
       "          356,   760,   470,    13,   198,   198,  5962, 22307,    25,\n",
       "          198,  5756,   514,  1494,   683,    11,   290,   356,  1183,\n",
       "          423, 11676,   379,   674,   898,  2756,    13,   198,  3792,\n",
       "          470,   257, 15593,    30,   198,   198,  3237,    25,   198,\n",
       "         2949],\n",
       "       [  198,   198,  5962, 22307,    25,   198,  1639,   389,   477,\n",
       "        12939,  2138,   284,  4656,   621,   284,  1145,   680,    30,\n",
       "          198,   198,  3237,    25,   198,  4965,  5634,    13, 12939,\n",
       "           13,   198,   198,  5962, 22307,    25,   198,  5962,    11,\n",
       "          345,   760,   327,  1872,   385,  1526, 28599,   318,  4039,\n",
       "         4472,   284,   262,   661,    13,   198,   198,  3237,    25,\n",
       "          198,  1135,   760,   470,    11,   356,   760,   470,    13,\n",
       "          198,   198,  5962, 22307,    25,   198,  5756,   514,  1494,\n",
       "          683,    11,   290,   356,  1183,   423, 11676,   379,   674,\n",
       "          898,  2756,    13,   198,  3792,   470,   257, 15593,    30,\n",
       "          198,   198,  3237,    25,   198,  2949,   517,  3375,   319,\n",
       "          470],\n",
       "       [   25,   198,  1639,   389,   477, 12939,  2138,   284,  4656,\n",
       "          621,   284,  1145,   680,    30,   198,   198,  3237,    25,\n",
       "          198,  4965,  5634,    13, 12939,    13,   198,   198,  5962,\n",
       "        22307,    25,   198,  5962,    11,   345,   760,   327,  1872,\n",
       "          385,  1526, 28599,   318,  4039,  4472,   284,   262,   661,\n",
       "           13,   198,   198,  3237,    25,   198,  1135,   760,   470,\n",
       "           11,   356,   760,   470,    13,   198,   198,  5962, 22307,\n",
       "           25,   198,  5756,   514,  1494,   683,    11,   290,   356,\n",
       "         1183,   423, 11676,   379,   674,   898,  2756,    13,   198,\n",
       "         3792,   470,   257, 15593,    30,   198,   198,  3237,    25,\n",
       "          198,  2949,   517,  3375,   319,   470,    26,  1309,   340,\n",
       "          307]], dtype=int32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 100\n",
    "stride = 4\n",
    "batch_size = 8\n",
    "\n",
    "data = DataLoader(x, stride, max_length)\n",
    "dataset = data.load_data(batch_size)\n",
    "next(iter(dataset))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "762f1b7e-cdf5-4119-98cb-0238ba7acf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257          # Size of the token dictionary\n",
    "output_dim = 256            # Size of the embedding\n",
    "context_len = max_length    # To create the positional embedding\n",
    "\n",
    "# Create an embedding for each token (A vector representation of that token)\n",
    "token_embedding = keras.layers.Embedding(vocab_size, output_dim)(next(iter(dataset))[0])\n",
    "\n",
    "# Create a positional embedding which has information of the word position\n",
    "pos_idx = tf.range(context_len)\n",
    "pos_embedding = keras.layers.Embedding(context_len, output_dim)(pos_idx)\n",
    "\n",
    "# Add the positional information to the original token embedding\n",
    "input_embedding = token_embedding + pos_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82519c58-4348-4be2-ae9b-8898ae9527d3",
   "metadata": {},
   "source": [
    "## Creating a Simple Self Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e5da636-d4c7-4e3a-b01c-0ebbff144a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Attention(inputs):\n",
    "    \"\"\"\n",
    "    A very simple implementation of the Self Attention Layer\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Calculate the relationship between each input and all other inputs in the sequence\n",
    "    attention_scores = tf.matmul(inputs, tf.transpose(inputs))\n",
    "\n",
    "    # 2. Normalize the attention scores for better learning (better for gradient descent)\n",
    "    norm_as = keras.layers.Softmax()(attention_scores)\n",
    "\n",
    "    # 3. generate the final context vector by multiplying each attention score with \n",
    "    # its corresponding input and suming them up\n",
    "    final_context_vec = tf.matmul(norm_as, inputs)\n",
    "\n",
    "    return final_context_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4911613a-b988-40ab-84d7-8e8edc7bd9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8, 100, 256])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embedding.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb98eb9-9f91-44cd-966b-bbf05f1740aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(keras.Layer):\n",
    "    def __init__(self, dim, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # The dimention of the query, key and value weights\n",
    "        self.dim = dim\n",
    "        self.bias = bias\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Initializing the query, key and value weights\n",
    "        \"\"\"\n",
    "        Use the keras weight matrices to initialize the weights \n",
    "            self.Wq = self.add_weight((input_shape[-1], self.dim), name=\"Wq\")\n",
    "            self.Wk = self.add_weight((input_shape[-1], self.dim), name=\"Wk\")\n",
    "            self.Wv = self.add_weight((input_shape[-1], self.dim), name=\"Wv\")\n",
    "        \"\"\"        \n",
    "\n",
    "        # Use the keras dense layer for the weights initialization\n",
    "        self.Wq = keras.layers.Dense(self.dim, use_bias=self.bias)\n",
    "        self.Wk = keras.layers.Dense(self.dim, use_bias=self.bias)\n",
    "        self.Wv = keras.layers.Dense(self.dim, use_bias=self.bias)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        #Calculate keys, queries and values vectors \n",
    "        \"\"\"\n",
    "        Calculate the vectors using dot product\n",
    "            keys = K.dot(inputs, self.Wk)\n",
    "            queries = K.dot(inputs, self.Wq)\n",
    "            values = K.dot(inputs, self.Wv)\n",
    "        \"\"\"\n",
    "        # Calculate the vectors using the dense layer which is functionaly the same as doing a dot product\n",
    "        keys = self.Wk(inputs)\n",
    "        queries = self.Wq(inputs)\n",
    "        values = self.Wv(inputs)\n",
    "\n",
    "        attention_score = K.dot(queries, K.transpose(keys))\n",
    "\n",
    "        attention_weights = K.softmax(attention_score / self.dim**0.5, axis=-1)\n",
    "\n",
    "        context_vector = K.dot(attention_weights, values)\n",
    "\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "904cc28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CasualSelfAttention(keras.Layer):\n",
    "    def __init__(self, dim, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # The dimention of the query, key and value weights\n",
    "        self.dim = dim\n",
    "        self.bias = bias\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Initializing the query, key and value weights\n",
    "        # Use the keras dense layer for the weights initialization\n",
    "        self.Wq = keras.layers.Dense(self.dim, use_bias=self.bias)\n",
    "        self.Wk = keras.layers.Dense(self.dim, use_bias=self.bias)\n",
    "        self.Wv = keras.layers.Dense(self.dim, use_bias=self.bias)\n",
    "\n",
    "    def mask(self, attention_scores):\n",
    "        # Create & Apply a mask on the attention scores\n",
    "        context_length = attention_scores.shape[0]\n",
    "        mask = K.triu(K.ones((context_length,context_length)), k=1)\n",
    "        mask = K.cast(mask, tf.bool)\n",
    "        \n",
    "        # Apply the mask to the attention scores\n",
    "        # Areas where the mask is true is set to -inf to ensure 0 when calculating the softmax\n",
    "        masked_attention = K.where(mask, -np.inf, attention_scores)\n",
    "        return masked_attention\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        #Calculate keys, queries and values vectors \n",
    "        # Calculate the vectors using the dense layer which is functionaly the same as doing a dot product\n",
    "        keys = self.Wk(inputs)\n",
    "        queries = self.Wq(inputs)\n",
    "        values = self.Wv(inputs)\n",
    "        \n",
    "        attention_scores = K.dot(queries, K.transpose(keys))\n",
    "        masked_attention = self.mask(attention_scores)\n",
    "\n",
    "        attention_weights = K.softmax(masked_attention / self.dim**0.5, axis=-1)\n",
    "        \n",
    "        context_vector = K.dot(attention_weights, values)\n",
    "\n",
    "        return context_vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4e371915-bd4e-499a-bc28-2c7c43e88232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 256), dtype=float32, numpy=\n",
       "array([[-0.02131266,  0.06561862,  0.0551003 , ..., -0.02843301,\n",
       "         0.00802045, -0.02614996],\n",
       "       [ 0.01608673,  0.06855912,  0.02218414, ..., -0.01544351,\n",
       "        -0.01108414, -0.02163525],\n",
       "       [ 0.03635468,  0.04834025,  0.01675467, ..., -0.00699243,\n",
       "        -0.00565207, -0.01421074],\n",
       "       ...,\n",
       "       [ 0.01456432,  0.00418853, -0.01226066, ...,  0.01061585,\n",
       "        -0.01198308, -0.00576923],\n",
       "       [ 0.01436179,  0.00448983, -0.0117574 , ...,  0.01000056,\n",
       "        -0.01217003, -0.00531628],\n",
       "       [ 0.01350324,  0.00466125, -0.01120132, ...,  0.00958462,\n",
       "        -0.01139006, -0.00473438]], dtype=float32)>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_attention = CasualSelfAttention(256)\n",
    "self_attention(input_embedding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0a56d4ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DType' object is not callable"
     ]
    }
   ],
   "source": [
    "tf.bool()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093ea648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow18",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
